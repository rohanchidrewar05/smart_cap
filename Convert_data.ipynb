{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convert_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanchidrewar05/smart_cap/blob/master/Convert_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0ViIFIsrDid8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ec81900f-d883-48f0-c581-01693b5e7b41"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install face_recognition"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.14.6)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (4.0.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->face_recognition) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9rPsOe_6DhkJ",
        "colab_type": "code",
        "outputId": "d367986d-a2a2-408d-9860-fecdb0830fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import face_recognition\n",
        "import cv2\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AKRxDvN8Ne3-",
        "colab_type": "code",
        "outputId": "31dcc60d-1686-4c13-8b9d-c6161ce3e881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\"\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Bays Classifier.ipynb'   KNN.ipynb\t       test_converted_data\n",
            " Classifier.ipynb\t  Models\t       torch0.ipynb\n",
            " Convert_data.ipynb\t 'Previous Datasets'   Untitled0.ipynb\n",
            " Converted_data\t\t  SVM.ipynb\t      'Untitled spreadsheet.gsheet'\n",
            " Dataset\t\t  Temp\n",
            " face_classifier.ipynb\t  temp.ipynb\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ijiJn4byDhkW",
        "colab_type": "code",
        "outputId": "1cd14c98-7139-4133-accc-75d81d01bf3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    data_path = \"/content/drive/My Drive/Colab Notebooks/Dataset\"\n",
        "    data_save_path = \"/content/drive/My Drive/Colab Notebooks/Converted_data\"\n",
        "    test_data_save_path = \"/content/drive/My Drive/Colab Notebooks/test_converted_data\"\n",
        "    print(\"Loading dataset from : \", data_path)\n",
        "    files = os.listdir(data_path)\n",
        "    X = []\n",
        "    Y = []\n",
        "    X_test = []\n",
        "    Y_test = []\n",
        "    print(\"Loading data ....\")\n",
        "    print(files)\n",
        "    temp = 0                         \n",
        "    for i in range(len(files)):\n",
        "      path = os.path.join(data_path,files[i])\n",
        "      files1 = os.listdir(path)\n",
        "      files1.sort()\n",
        "      print(files1)\n",
        "      for j in range(len(files1)):\n",
        "        image = cv2.imread(os.path.join(path,files1[j]))\n",
        "        face_bounding_boxes = face_recognition.face_locations(image)\n",
        "        check = False\n",
        "        \n",
        "        if(len(face_bounding_boxes) == 1):\n",
        "          check = True\n",
        "          encoding = face_recognition.face_encodings(image,known_face_locations = face_bounding_boxes)[0]\n",
        "        \n",
        "        elif(len(face_bounding_boxes) > 1):\n",
        "          check = True\n",
        "          max_area = 0\n",
        "          max_loc = 0\n",
        "          for i in range(len(face_bounding_boxes)):\n",
        "            box = face_bounding_boxes[i] \n",
        "            area = (box[0]-box[2])*(box[3]-box[1])\n",
        "            if(max_area < area):\n",
        "              area = max_area\n",
        "              max_box = i\n",
        "          templist = []\n",
        "          templist.append(face_bounding_boxes[max_box])\n",
        "          encoding = face_recognition.face_encodings(image,known_face_locations = templist)[0]\n",
        "        \n",
        "        if(j < 0.8 * len(files1)):\n",
        "          if(check):\n",
        "            X.append(encoding)\n",
        "            Y.append(i)\n",
        "\n",
        "        else:\n",
        "          if(check):\n",
        "            X_test.append(encoding)\n",
        "            Y_test.append(i)\n",
        "            \n",
        "            \n",
        "    print(\"Data loading completed.\")\n",
        "    print(\"Saving the data...\")\n",
        "   \n",
        "    if data_save_path is not None:\n",
        "        with open(os.path.join(data_save_path,\"embedding.txt\"), 'wb') as f:\n",
        "            pickle.dump(X, f)\n",
        "        with open(os.path.join(data_save_path,\"label.txt\"), 'wb') as f:\n",
        "            pickle.dump(Y, f)\n",
        "        \n",
        "    if test_data_save_path is not None:\n",
        "        with open(os.path.join(test_data_save_path,\"test_embedding.txt\"), 'wb') as f:\n",
        "            pickle.dump(X_test, f)\n",
        "        with open(os.path.join(test_data_save_path,\"test_label.txt\"), 'wb') as f:\n",
        "            pickle.dump(Y_test, f)\n",
        "    print(\"Saving data is completed.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset from :  /content/drive/My Drive/Colab Notebooks/Dataset\n",
            "Loading data ....\n",
            "['kedar', 'semanto', 'neelima', 'pawan', 'pragya', 'ujwala', 'rohan']\n",
            "['0', '1', '10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '10', '11', '12', '13', '14', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "Data loading completed.\n",
            "Saving the data...\n",
            "Saving data is completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5wzr06yEwxlK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "change_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4zQyEs__CeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def change_names():\n",
        "    data_path = \"/content/drive/My Drive/Colab Notebooks/Dataset/\"\n",
        "    print(data_path)\n",
        "    files = os.listdir(data_path)\n",
        "    print(files)\n",
        "    for i in range(len(files)):\n",
        "      path = os.path.join(data_path,files[i])\n",
        "      files1 = os.listdir(path)\n",
        "      print(len(files1))\n",
        "      for j in range(len(files1)):\n",
        "        #print(os.path.join(path,files1[j]))\n",
        "        prev_name = files1[j]\n",
        "        new_name = \"%#04d\" %(j,)\n",
        "        print(prev_name,new_name)\n",
        "        os.rename(os.path.join(path,prev_name),os.path.join(path,new_name))\n",
        "    print(\"Dataset renaming is completed\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}